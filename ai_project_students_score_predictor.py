# -*- coding: utf-8 -*-
"""ai_project_students_score _predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oHscQ5Qny8vhD0cLejrHbmdOGkxph5vG

# 1. Train the Model
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import pandas as pd
import numpy as np
import joblib
from google.colab import files
import io
from math import sqrt

uploaded = files.upload()
filename = next(iter(uploaded))
df = pd.read_csv(io.BytesIO(uploaded[filename]))

# identifying dataset target colomn names
assessment_cols = sorted([col for col in df.columns if col.startswith("assessment_score_")])

# dataset must have record for atleast 4 assessments
N = 4
X = []
y = []

for row in df[assessment_cols].values:
    if len(row) >= N + 1:
        for i in range(len(row) - N):
            X.append(row[i:i+N])
            y.append(row[i+N])

X = np.array(X)
y = np.array(y)

if len(X) == 0:
    raise ValueError("Not enough data to train the model.")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestRegressor(n_estimators=200, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
rmse = sqrt(mean_squared_error(y_test, y_pred))
print(f"Model training Successful.\nRMSE: {rmse:.2f}%")

joblib.dump(model, 'student_marks_predictor.pkl')
print("Model saved as 'student_marks_predictor.pkl'")

"""# 2. Computing Metrics of Model
This Section contains results of different tests run on the trained model.

## Numeric Metrics
"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# perform prediction
y_pred = model.predict(X_test)

# standard metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = mse ** 0.5
r2 = r2_score(y_test, y_pred)

print(f"MAE:  {mae:.2f}%")
print(f"MSE:  {mse:.2f}")
print(f"RMSE: {rmse:.2f}%")
print(f"RÂ²:   {r2:.4f}")

"""## Predicted vs Actual"""

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, color='blue', edgecolor='k')
plt.plot([0, 100], [0, 100], '--r', label='Perfect Prediction')
plt.xlabel("Actual Score (%)")
plt.ylabel("Predicted Score (%)")
plt.title("Predicted vs Actual Assessment Scores")
plt.legend()
plt.grid(True)
plt.show()

"""## Residual Plot"""

residuals = y_test - y_pred

plt.figure(figsize=(8, 6))
plt.scatter(y_pred, residuals, alpha=0.6, color='purple', edgecolor='k')
plt.axhline(0, linestyle='--', color='gray')
plt.xlabel("Predicted Score (%)")
plt.ylabel("Residual (Actual - Predicted)")
plt.title("Residual Plot")
plt.grid(True)
plt.show()

"""## Histogram of Errors"""

plt.figure(figsize=(8, 6))
plt.hist(residuals, bins=20, color='green', edgecolor='black')
plt.title("Distribution of Prediction Errors (Residuals)")
plt.xlabel("Error")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

"""# 3. Run of the Model"""

import joblib

model = joblib.load('student_marks_predictor.pkl')

# number of input assessment scores
N = 4

print(f"\nðŸ“¥ Enter the last {N} assessment scores to predict the next one:")
user_input = [float(input(f"Score {i+1}: ")) for i in range(N)]

pred = model.predict([user_input])[0]
print(f"\nðŸ“Š Predicted next assessment score: {pred:.2f}%")